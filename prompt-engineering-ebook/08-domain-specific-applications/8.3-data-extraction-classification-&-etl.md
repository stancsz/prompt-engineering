# 8.3 Data Extraction, Classification, and ETL with LLMs

One of the most powerful applications of Large Language Models (LLMs) is their ability to process unstructured text and transform it into structured, actionable data. This capability is fundamental for tasks like **data extraction**, **classification**, and building **Extract, Transform, Load (ETL)** pipelines, enabling automation, analytics, and integration with traditional databases and business intelligence tools.

## Key Concepts

### 1. Data Extraction (Information Extraction)

**Definition:** Identifying and pulling specific pieces of information (entities, facts, relationships) from unstructured text and presenting them in a structured format.

*   **Named Entity Recognition (NER):** Identifying and categorizing named entities in text into predefined categories (e.g., person, organization, location, date, product).
    *   **Prompting:** Instruct the LLM to "extract all [entity type]," "list all [entity type] mentioned," or "identify [entity type] and their [attribute]." Often combined with structured output formats like JSON.
*   **Relationship Extraction:** Identifying semantic relationships between entities (e.g., "CEO of [Company]," "born in [Year]").
    *   **Prompting:** Instruct the LLM to "identify relationships between X and Y," or "list all [relationship type] between entities."
*   **Key-Value Pair Extraction:** Pulling specific data points and their associated values.
    *   **Prompting:** "Extract the [field name] and [another field name] as a JSON object."

### 2. Classification

**Definition:** Assigning predefined labels or categories to a piece of text based on its content.

*   **Sentiment Analysis:** Classifying text as positive, negative, or neutral sentiment.
*   **Topic Classification:** Categorizing documents or sentences by subject matter (e.g., "sports," "finance," "technology").
*   **Intent Classification:** Identifying the user's goal in a conversational turn (e.g., "order food," "check balance").
*   **Prompting:**
    *   **Zero-Shot:** "Classify the following text as [Label A], [Label B], or [Label C]."
    *   **Few-Shot:** Provide examples of text-label pairs to guide the model, especially for nuanced or domain-specific categories.
    *   **Output Format:** Instruct the model to output only the label, or the label within a structured format.

### 3. ETL Workflow with LLMs

**Definition:** A data integration process that involves:
*   **Extract:** Reading data from a source (often unstructured text).
*   **Transform:** Converting the extracted data into a desired structured format, cleaning it, or enriching it.
*   **Load:** Writing the transformed data into a target system (e.g., database, spreadsheet, data warehouse).

LLMs can automate the "Extract" and "Transform" stages, especially for data that is difficult to parse with traditional rule-based or regex methods.

## Example Prompts

### Data Extraction

*   **Extracting Entities as JSON:**
    ```
    You are a data extraction API. From the following job description, extract the 'Job Title', 'Company Name', 'Location', 'Required Skills' (as a list), and 'Experience Level'. Return the output as a JSON object. If a field is not found, use null.

    ### JOB DESCRIPTION ###
    We are seeking a highly motivated Senior Software Engineer at TechCorp in San Francisco. The ideal candidate will have 5+ years of experience with Python, Java, and cloud platforms. Experience with machine learning is a plus.
    ```
*   **Extracting Multiple Records:**
    ```
    Extract all customer names and their corresponding order IDs from the following log entries. Return the data as a JSON array of objects, where each object has 'customer_name' and 'order_id' keys.

    ### LOG ENTRIES ###
    [2023-10-26 10:05:12] User: Alice Johnson, Order: #A1B2C3D4
    [2023-10-26 10:10:30] Guest: Bob Williams, Order: #E5F6G7H8
    [2023-10-26 10:15:45] User: Charlie Brown, Order: #I9J0K1L2
    ```

### Classification

*   **Sentiment Classification (Few-Shot):**
    ```
    Classify the sentiment of the following product reviews as 'Positive', 'Negative', or 'Neutral'.

    ### EXAMPLES ###
    Review: "This product is amazing, I love it!"
    Sentiment: Positive

    Review: "It broke after one use, very disappointed."
    Sentiment: Negative

    Review: "It works as expected, nothing special."
    Sentiment: Neutral

    ### NEW REVIEW ###
    Review: "The delivery was slow, but the quality is good."
    Sentiment:
    ```
*   **Topic Classification:**
    ```
    Categorize the following news headline into one of these topics: 'Politics', 'Technology', 'Sports', 'Business', 'Health'.

    ### HEADLINE ###
    New AI breakthrough promises faster drug discovery.
    Topic:
    ```

### Transformation (ETL)

*   **CSV to JSON Transformation:**
    ```
    You are a data transformer. Convert the following CSV data into a JSON array of objects. Each object should represent a row, with column headers as keys.

    ### CSV DATA ###
    Name,Age,City
    Alice,30,New York
    Bob,24,London
    Charlie,35,Paris
    ```
*   **Reformatting Dates:**
    ```
    You are a date formatter. Convert all dates in the following text to 'YYYY-MM-DD' format.

    ### TEXT ###
    The meeting is scheduled for January 15th, 2024. The deadline was 3/1/23.
    ```

## Hands-On Exercise: Building an LLM-Powered ETL Pipeline

*Note: This exercise requires a Python environment with `openai` and `pandas` (`pip install openai pandas`)*

1.  **Prepare Unstructured Data:** Create a text file named `customer_feedback.txt` with several lines of unstructured customer feedback, including names, product mentions, and issues.
    ```
    Customer feedback:
    "John Doe: The new 'Quantum Speaker' has excellent sound, but the setup was confusing. Order #12345."
    "Jane Smith: My 'Eco-Blender' arrived damaged on 2023-11-01. I need a replacement. Order #67890."
    "Mark Lee: Very happy with the 'AeroDrone'. Received it on 12/15/2023. No issues."
    ```
2.  **Design Extraction Prompt:**
    *   Create a prompt to extract `customer_name`, `product_name`, `order_id`, `issue` (if any), and `delivery_date` from each line.
    *   Instruct the LLM to output each extracted record as a JSON object.
    *   Use a loop to process each line of feedback.

    ```python
    import os
    import json
    import pandas as pd
    from openai import OpenAI

    client = OpenAI() # Assumes OPENAI_API_KEY is set

    feedback_lines = []
    with open("customer_feedback.txt", "r") as f:
        for line in f:
            if line.strip(): # Skip empty lines
                feedback_lines.append(line.strip())

    extracted_data = []

    extraction_prompt_template = """
    Extract the following details from the customer feedback:
    - customer_name (string)
    - product_name (string)
    - order_id (string)
    - issue (string, or null if no issue)
    - delivery_date (string, in YYYY-MM-DD format, or null if not mentioned)

    Return the extracted data as a JSON object. If a field is not found, use null.

    Customer Feedback: "{feedback_text}"

    JSON Output:
    """

    for i, line in enumerate(feedback_lines):
        print(f"Processing line {i+1}: {line}")
        prompt = extraction_prompt_template.format(feedback_text=line)
        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.0, # Aim for deterministic output
                response_format={"type": "json_object"} # Request JSON output
            )
            json_output = json.loads(response.choices[0].message.content)
            extracted_data.append(json_output)
            print(f"Extracted: {json_output}")
        except Exception as e:
            print(f"Error extracting from line {i+1}: {e}")
            extracted_data.append({"error": str(e), "original_text": line})
        
        # Add a small delay to avoid rate limits
        import time
        time.sleep(0.1)

    # 3. Transform and Load into Pandas DataFrame (and then CSV)
    df = pd.DataFrame(extracted_data)
    df.to_csv("extracted_feedback.csv", index=False)
    print("\nExtracted data saved to extracted_feedback.csv")
    print(df)
    ```
3.  **Run and Verify:** Execute the Python script. Check the `extracted_feedback.csv` file and the printed DataFrame.
    *   Are all entities correctly extracted?
    *   Is the JSON format consistent?
    *   Are dates correctly formatted?

## Reflection

*   How did instructing the LLM to output JSON simplify the parsing process compared to free-form text?
*   What challenges did you face in ensuring consistent extraction (e.g., handling variations in date formats, missing information)?
*   How would you handle a very large `customer_feedback.txt` file that exceeds the LLM's context window? (Hint: revisit Chapter 4.4).
*   How does LLM-powered extraction compare to traditional regex or rule-based methods in terms of flexibility and maintenance?

## Evaluation Metrics (Revisited)

*   **Extraction:** Precision, Recall, F1-score (comparing extracted entities to ground truth labels). Human review for quality.
*   **Classification:** Accuracy, Precision, Recall, F1-score (standard classification metrics).
*   **Transformation:** Manual inspection, schema validation for structured outputs.

## Challenges and Best Practices

### Challenges:

*   **Inconsistent Output Formats:** LLMs can deviate from requested formats, requiring robust parsing and validation.
*   **Hallucinations in Extraction:** The model might invent entities or values not present in the text.
*   **Ambiguity:** Ambiguous text can lead to incorrect classifications or extractions.
*   **Scalability:** Processing large volumes of text can be costly and slow.
*   **Data Quality:** Poor input text quality (typos, grammatical errors) can degrade performance.
*   **Schema Evolution:** Changes in desired output schema require prompt updates.

### Best Practices:

*   **Explicitly Request Structured Output:** Always instruct the LLM to output JSON, XML, or CSV. Provide a schema or examples.
*   **Use Few-Shot Examples:** For complex extraction or classification tasks, provide 1-3 examples of input-output pairs.
*   **Validate Output:** Implement programmatic validation (e.g., JSON schema validation) to ensure the LLM's output adheres to the expected structure.
*   **Error Handling:** Gracefully handle cases where the LLM fails to produce the correct format or extracts incorrect data.
*   **Iterate and Refine:** Continuously test and improve your extraction/classification prompts.
*   **Chain Prompts:** For complex ETL, break it into multiple LLM calls (e.g., extract, then classify, then transform).
*   **RAG for Context:** For domain-specific extraction, use RAG to provide relevant definitions or examples.
*   **Cost Optimization:** Be mindful of token usage, especially for large inputs.
*   **Human-in-the-Loop:** For critical data, incorporate human review of extracted/classified data.
