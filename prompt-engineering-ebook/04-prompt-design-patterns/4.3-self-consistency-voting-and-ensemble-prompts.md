# 4.3 Self-Consistency, Voting, and Ensemble Prompts

While Chain-of-Thought (CoT) prompting significantly improves the reasoning capabilities of LLMs, the model's output can still be sensitive to the specific sampling path taken during generation. To further enhance reliability, robustness, and accuracy, especially for critical applications, prompt engineers can employ **ensemble methods**. These techniques involve generating multiple outputs and then aggregating them to arrive at a more robust and often more accurate final answer.

## 1. Self-Consistency

**Definition:** Self-consistency is a decoding strategy that leverages the idea that complex problems often have multiple valid reasoning paths leading to the same correct answer. Instead of relying on a single Chain-of-Thought trace, it samples multiple diverse reasoning paths and then aggregates their final answers by majority vote.

*   **Mechanism:**
    1.  **Generate Multiple CoT Paths:** Given a prompt that encourages Chain-of-Thought reasoning (e.g., "Let's think step by step"), generate `N` independent outputs. This is typically done by setting a higher `temperature` (e.g., 0.7-1.0) to encourage diversity in the reasoning paths.
    2.  **Extract Final Answers:** From each of the `N` generated CoT outputs, extract only the final answer.
    3.  **Aggregate by Majority Vote:** The final answer is determined by taking the majority vote among the extracted answers. If there's a tie, further strategies like picking the shortest answer, or prompting the model to resolve the tie, can be employed.
*   **Benefit:** Self-consistency significantly reduces errors on complex reasoning tasks (like arithmetic or common sense reasoning) by mitigating the impact of individual reasoning errors or "hallucinations" in a single CoT trace. It acts as a form of error correction.
*   **When to Use:** Highly recommended for tasks where accuracy on multi-step reasoning is critical, and a slight increase in latency/cost is acceptable.

**Example:**
**Prompt:**
```
Question: A baker has 3 dozen eggs. He uses 18 eggs for a cake. How many eggs does he have left?
Let's think step by step.
```

**Generate 5 diverse CoT outputs (e.g., with temperature=0.7):**

*   **Output 1:**
    1.  1 dozen = 12 eggs.
    2.  3 dozen = 3 * 12 = 36 eggs.
    3.  Used 18 eggs: 36 - 18 = 18.
    *   **Final Answer: 18**
*   **Output 2:**
    1.  Total eggs: 3 * 12 = 36.
    2.  Eggs left: 36 - 18 = 18.
    *   **Final Answer: 18**
*   **Output 3:**
    1.  3 dozen is 36 eggs.
    2.  He used 18.
    3.  36 minus 18 is 18.
    *   **Final Answer: 18**
*   **Output 4:**
    1.  3 dozen eggs means 3 * 12 = 36 eggs.
    2.  He used 18 eggs.
    3.  Remaining eggs = 36 - 18 = 18.
    *   **Final Answer: 18**
*   **Output 5:**
    1.  One dozen is 12. Three dozen is 36.
    2.  He used 18.
    3.  36 - 18 = 17. (Incorrect reasoning step)
    *   **Final Answer: 17**

**Aggregation:**
*   Answers: {18, 18, 18, 18, 17}
*   Majority Vote: **18**

## 2. Voting (for Classification/Categorization)

**Definition:** Voting is a simpler ensemble technique primarily used for classification, categorization, or selection tasks. It involves generating multiple independent predictions for the same input and then selecting the most frequent (majority) prediction.

*   **Mechanism:**
    1.  **Generate Multiple Predictions:** Send the same prompt (e.g., a classification prompt) to the LLM multiple times.
    2.  **Collect Labels/Categories:** Extract the predicted label or category from each output.
    3.  **Majority Vote:** The final prediction is the label that appears most frequently.
*   **Benefit:** Increases the reliability of classification tasks, especially when individual predictions might be uncertain or when dealing with ambiguous inputs.
*   **Use Cases:** Sentiment analysis, topic classification, spam detection, intent recognition, or any task where the output is a discrete category.

**Example:**
**Prompt:**
```
Classify the sentiment of the following movie review as 'Positive', 'Negative', or 'Neutral'.

Review: "The acting was superb, but the ending felt rushed."
Sentiment:
```

**Generate 7 predictions (e.g., with temperature=0.5):**
*   Prediction 1: `Positive`
*   Prediction 2: `Neutral`
*   Prediction 3: `Positive`
*   Prediction 4: `Neutral`
*   Prediction 5: `Positive`
*   Prediction 6: `Positive`
*   Prediction 7: `Neutral`

**Aggregation:**
*   Counts: Positive: 4, Neutral: 3, Negative: 0
*   Majority Vote: **Positive**

## 3. Ensemble Prompts (Prompt Chaining/Diversity)

**Definition:** Ensemble prompts involve using *different* prompt formulations, strategies, or even different LLM models to generate outputs for the same task, and then combining or selecting the best result. This leverages the idea that different prompts might elicit different strengths from the model.

*   **Mechanism:**
    1.  **Design Diverse Prompts:** Create several distinct prompts for the same task. These could vary in:
        *   **Instruction Style:** Direct instruction vs. role-playing.
        *   **Examples:** Different few-shot examples.
        *   **Reasoning Strategy:** CoT vs. direct answer.
        *   **Negative Constraints:** Different "do not" instructions.
    2.  **Generate Outputs:** Send the input to the LLM with each distinct prompt.
    3.  **Aggregate/Select:**
        *   **Consensus:** If outputs are categorical, use voting.
        *   **Quality Score:** If outputs are generative, use an evaluation metric (automated or human) to select the best one.
        *   **Hybrid:** Combine parts of different outputs.
*   **Benefit:** Can achieve higher performance than any single prompt by exploiting the complementary strengths of different prompting strategies.
*   **Use Cases:** Complex content generation, creative tasks, or when a single prompt struggles to consistently produce high-quality results.

**Example:**
**Task:** Generate a short, engaging social media caption for a new product.

*   **Prompt A (Role-based):** `You are a witty social media manager. Write a short, engaging caption for our new product: [Product Name].`
*   **Prompt B (Instruction-based with constraints):** `Generate a social media caption for [Product Name]. Keep it under 100 characters and include a call to action.`
*   **Prompt C (Example-based):** `Here are some examples of good social media captions: [Examples]. Now, write one for [Product Name].`

**Aggregation:** Generate outputs from all three. A human or an automated evaluator (e.g., another LLM) could then select the best one, or a system could combine elements if appropriate.

## When to Use Ensemble Methods

Ensemble methods are powerful but come with increased computational overhead. They are most justified when:

*   **High Accuracy is Critical:** For applications where errors are costly (e.g., medical, financial, legal).
*   **Complex Reasoning Tasks:** When single prompts or CoT alone are insufficient.
*   **Variability in Model Output:** When the LLM's responses are inconsistent or prone to "flips" between correct and incorrect answers.
*   **Debugging and Robustness:** To gain confidence in the model's output and identify areas where prompts might be weak.

## Hands-On Exercise: Implementing Self-Consistency

1.  **Choose a Multi-Step Problem:** Use the same type of arithmetic or logic problem from Chapter 4.2 (e.g., "If a recipe calls for 2.5 cups of flour for 12 cookies, how much flour is needed for 30 cookies?").
2.  **Prepare the CoT Prompt:**
    ```
    Solve the following problem. Show your work step by step and then state the final answer.

    Problem: [Your chosen problem]
    ```
3.  **Generate Multiple Samples:**
    *   Using an LLM API or playground, run this prompt 5-7 times.
    *   Crucially, set `temperature` to a moderate value (e.g., 0.7) to encourage diverse reasoning paths.
    *   Collect the full output (including steps and final answer) for each run.
4.  **Extract and Aggregate:**
    *   Manually (or programmatically if comfortable) extract the final answer from each of the 5-7 outputs.
    *   Count the occurrences of each unique final answer.
    *   Identify the majority answer.
5.  **Compare:** How does this majority answer compare to a single run with `temperature=0.0` (greedy decoding) or a single run with `temperature=0.7`?

## Reflection

*   Did self-consistency improve the correctness of the answer for your chosen problem?
*   Did you observe different reasoning paths leading to the same correct answer?
*   What are the practical challenges of implementing self-consistency in a production system (e.g., parsing outputs, managing multiple API calls)?
*   How might you adapt this self-consistency approach for a classification task (i.e., simple voting)?

## Limitations and Considerations

*   **Increased Cost and Latency:** Generating multiple outputs means more API calls and longer response times.
*   **Parsing Complexity:** Extracting the final answer from CoT outputs can require robust parsing logic.
*   **Diminishing Returns:** Beyond a certain number of samples, the accuracy gains may diminish while costs continue to rise.
*   **Not for All Tasks:** Less beneficial for simple, deterministic tasks where the model is already highly accurate with a single prompt.
*   **Tie-Breaking:** Strategies are needed to handle cases where there isn't a clear majority vote.
