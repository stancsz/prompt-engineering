# 2.3 Tokenization, Embeddings, and Vector Spaces

To effectively engineer prompts and truly harness the power of Large Language Models (LLMs), it is essential to peer "under the hood" and understand how these models process and represent human language internally. This involves three interconnected and fundamental concepts: **tokenization**, **embeddings**, and **vector spaces**. These mechanisms are the bedrock upon which LLMs build their understanding, transforming human-readable text into the numerical format that enables complex computations, directly influencing prompt length, context understanding, and advanced retrieval capabilities.

## 1. Tokenization: Breaking Down Text into LLM-Digestible Units

**Definition:** **Tokenization** is the initial and crucial process of converting raw, human-readable text into smaller, discrete units called *tokens*. These tokens are the fundamental numerical building blocks that Large Language Models (LLMs) operate on. A token can represent a whole word, a subword (a part of a word), a single character, or even a punctuation mark.

*   **Why it's Necessary:** LLMs are complex mathematical models that process numerical data, not raw text strings. Tokenization serves as the essential bridge, mapping textual information into a numerical format (token IDs) that the model can understand and compute with.
*   **Common Methods:** While simple word-based or character-based tokenization exists, modern LLMs predominantly use **subword tokenization** methods. These methods strike a balance between having a manageable vocabulary size and efficiently representing rare or out-of-vocabulary (OOV) words.
    *   **Byte-Pair Encoding (BPE):** A data compression algorithm adapted for tokenization. It iteratively merges the most frequent pairs of characters or subwords in a text corpus until a predefined vocabulary size is reached.
    *   **WordPiece:** Used by models like BERT, WordPiece is similar to BPE but merges subwords based on their likelihood of forming a new word, optimizing for language modeling tasks.
    *   **SentencePiece:** Employed by models such as T5, SentencePiece is a language-agnostic subword tokenizer that can be trained directly from raw text, handling multiple languages and special characters robustly.
    Subword tokenization's strength lies in its ability to represent any word by breaking it down into known subword units, thus handling rare or novel words effectively without resorting to an "unknown" token.

(Note to author: Consider adding a conceptual diagram here illustrating how a sentence like "Prompt engineering is fascinating!" might be tokenized into subwords, showing the resulting tokens and their numerical IDs.)

*   **Impact on Prompts:** Understanding tokenization has direct practical implications for prompt engineers:
    *   **Context Window Limits:** Every LLM has a maximum number of tokens it can process in a single input, known as the "context window." If your prompt (including any provided context or examples) exceeds this limit, the LLM will truncate it, potentially losing critical information. Knowing how your text translates into tokens is vital for managing prompt length.
    *   **Cost Implications:** Many LLM APIs charge based on the number of tokens processed (both input and output). Efficient and concise prompting, informed by tokenization awareness, can significantly reduce operational costs.
    *   **Granularity and Nuance:** The specific tokenizer used by an LLM can influence how it interprets subtle nuances, especially with rare words, domain-specific terminology, or even code. A word broken into multiple subwords might be processed differently than a single-token word.

**Hands-On Exercise: Observing Tokenization**
1.  **Access a Tokenizer Tool:** Utilize an online tokenizer tool (e.g., OpenAI's Tokenizer, Hugging Face's Tokenizer Playground) or a Python library (e.g., the `transformers` library from Hugging Face).
2.  **Simple Text Analysis:** Paste the phrase "Prompt engineering is fascinating!"
    *   Note the total token count.
    *   Observe how common words, punctuation, and spaces are handled (e.g., are spaces separate tokens? Is punctuation attached or separate?).
3.  **Complex Word Breakdown:** Try a long, uncommon word like "antidisestablishmentarianism" or a highly technical term from your domain.
    *   See how the tokenizer breaks it down into smaller subword units.
    *   Compare the token count to the character count for such words.
4.  **Code Snippet Tokenization:** Paste a short code snippet (e.g., `def factorial(n): return 1 if n == 0 else n * factorial(n-1)`).
    *   Analyze how the tokenizer handles programming keywords, variable names, operators, and symbols. Does it treat `def` as one token and `factorial` as another?


**Hands-On Exercise: Calculating Embedding Similarity**
1.  **Obtain Embeddings:** Use an embedding API (e.g., OpenAI's Embedding API) or a Python library (e.g., `sentence-transformers`) to generate embeddings for the following sentences:
    *   Sentence A: "Artificial intelligence is transforming industries."
    *   Sentence B: "AI is revolutionizing businesses."
    *   Sentence C: "The cat sat on the mat."
2.  **Compute Cosine Similarity:** Use the provided Python snippet (or a similar function in your chosen environment) to calculate the cosine similarity between:
    *   A and B
    *   A and C
    *   B and C

    ```python
    from sklearn.metrics.pairwise import cosine_similarity
    import numpy as np

    # Assume 'embedding_a', 'embedding_b', 'embedding_c' are numpy arrays
    # representing the embeddings of Sentence A, B, and C respectively.
    # For example:
    # embedding_a = np.array([...])
    # embedding_b = np.array([...])
    # embedding_c = np.array([...])

    similarity_ab = cosine_similarity(embedding_a.reshape(1, -1), embedding_b.reshape(1, -1))[0][0]
    similarity_ac = cosine_similarity(embedding_a.reshape(1, -1), embedding_c.reshape(1, -1))[0][0]
    similarity_bc = cosine_similarity(embedding_b.reshape(1, -1), embedding_c.reshape(1, -1))[0][0]

    print(f"Similarity (A, B): {similarity_ab:.4f}")
    print(f"Similarity (A, C): {similarity_ac:.4f}")
    print(f"Similarity (B, C): {similarity_bc:.4f}")
    ```
3.  **Analyze Results:** Observe how the similarity scores reflect the semantic relatedness of the sentences. Sentences A and B should have a high similarity, while those involving C should have lower scores.

## 3. Vector Spaces: Navigating the Semantic Landscape

**Concept:** The entire collection of all possible embeddings—for individual tokens, words, phrases, sentences, or even entire documents—forms a high-dimensional **vector space**. Within this abstract space, each piece of text is represented as a unique point (a vector). The remarkable aspect of this space is that its geometry directly encodes complex semantic relationships.

*   **Dimensionality:** These vector spaces are typically very high-dimensional, ranging from hundreds to thousands of dimensions (e.g., 768 dimensions for BERT-base models, 1536 for OpenAI's `text-embedding-ada-002`). While difficult for humans to intuitively grasp, these many dimensions allow for the capture of intricate semantic nuances.
*   **Semantic Relationships and Analogies:** The spatial relationships between vectors reflect their semantic relationships. Famous examples like "King - Man + Woman = Queen" illustrate that vector arithmetic can capture relational semantics. Moving in a specific direction within the vector space can correspond to a consistent change in meaning (e.g., gender, tense, country, or even sentiment).
*   **Visualization (Conceptual):** Directly visualizing a thousand-dimensional space is impossible. However, dimensionality reduction techniques like Principal Component Analysis (PCA) or t-Distributed Stochastic Neighbor Embedding (t-SNE) can project these high-dimensional vectors into a more comprehensible 2D or 3D space. While these projections are approximations, they often reveal meaningful clusters and relationships, allowing for visual inspection of semantic organization.
*   **Relevance to Prompting:** Understanding vector spaces is crucial for appreciating the underlying mechanism by which LLMs "reason" about meaning. When you craft a prompt, it is converted into a vector within this space. The LLM then generates a response by navigating this semantic landscape, aiming to produce an output vector that is semantically aligned with the prompt and its internal knowledge. Providing relevant context in your prompt effectively guides the model to a specific region of this vector space, leading to more targeted and desired outputs.

**Hands-On Exercise: Visualizing Embeddings (Conceptual)**
*Note: This exercise requires a Python environment with `numpy`, `scikit-learn`, and a plotting library like `matplotlib` or `plotly`.*
1.  **Generate Embeddings:** Obtain embeddings for a small, diverse set of sentences (e.g., 10-20 sentences covering distinct topics like "dogs," "cats," "cars," "computers," "weather," "sports").
2.  **Dimensionality Reduction:** Apply t-SNE to reduce the embeddings to 2 dimensions for plotting.
    ```python
    from sklearn.manifold import TSNE
    import matplotlib.pyplot as plt
    import numpy as np

    # Placeholder for your collected embeddings (replace with actual data)
    # Example: all_embeddings = np.array([[...], [...], ...])
    # Ensure all_embeddings is a 2D numpy array where each row is an embedding
    all_embeddings = np.random.rand(20, 1536) # Example: 20 sentences, 1536-dim embeddings
    sentence_labels = [
        "dogs bark", "puppies play", "canine friends", # Dog-related
        "cats purr", "kittens nap", "feline companions", # Cat-related
        "cars drive fast", "vehicles on road", "automobile traffic", # Car-related
        "computers process data", "laptops for work", "software development", # Computer-related
        "sunny weather today", "rainy forecast", "stormy skies", # Weather-related
        "football match", "basketball game", "tennis tournament" # Sports-related
    ]
    # Assign colors based on topic for visualization
    colors = ['red']*3 + ['blue']*3 + ['green']*3 + ['purple']*3 + ['orange']*3 + ['brown']*3

    tsne = TSNE(n_components=2, random_state=42, perplexity=min(5, len(all_embeddings)-1))
    reduced_embeddings = tsne.fit_transform(all_embeddings)

    # Plotting
    plt.figure(figsize=(10, 8))
    scatter = plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=colors, alpha=0.7)
    plt.title("2D t-SNE Projection of Sentence Embeddings")
    plt.xlabel("t-SNE Component 1")
    plt.ylabel("t-SNE Component 2")

    # Optional: Add labels for each point (can be cluttered for many points)
    # for i, txt in enumerate(sentence_labels):
    #     plt.annotate(txt, (reduced_embeddings[i, 0], reduced_embeddings[i, 1]), textcoords="offset points", xytext=(5,-5), ha='center')

    plt.grid(True, linestyle='--', alpha=0.6)
    plt.show()
    ```
3.  **Observe Clusters:** When you run this code with actual embeddings, you should visually observe that sentences about similar topics tend to cluster together in the 2D plot. This provides a tangible (though simplified) demonstration of the semantic organization captured within the high-dimensional vector space.

**Hands-On Exercise: Visualizing Embeddings (Conceptual)**
*Note: This exercise requires a Python environment with `numpy`, `scikit-learn`, and `matplotlib` or `plotly`.*
1.  **Generate Embeddings:** Obtain embeddings for a small, diverse set of sentences (e.g., 10-20 sentences about different topics like "dogs," "cats," "cars," "computers," "weather").
2.  **Dimensionality Reduction:** Apply t-SNE to reduce the embeddings to 2 dimensions.
    ```python
    from sklearn.manifold import TSNE
    import matplotlib.pyplot as plt
    import numpy as np

    # Assume 'all_embeddings' is a numpy array of shape (num_sentences, embedding_dim)
    # For example:
    # all_embeddings = np.array([...]) # Your collected embeddings

    tsne = TSNE(n_components=2, random_state=42, perplexity=min(5, len(all_embeddings)-1))
    reduced_embeddings = tsne.fit_transform(all_embeddings)

    # Plotting (conceptual - you'd need labels for each point)
    plt.figure(figsize=(8, 6))
    plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1])
    plt.title("2D t-SNE Projection of Sentence Embeddings")
    plt.xlabel("t-SNE Component 1")
    plt.ylabel("t-SNE Component 2")
    plt.show()
    ```
3.  **Observe Clusters:** If you label your points (e.g., color-code by topic), you should observe that sentences about similar topics tend to cluster together in the 2D plot, demonstrating the semantic organization of the vector space.

## Practical Implications for Prompt Engineering

*   **Context Window Management:** Be mindful of token limits. If your prompt and context exceed the limit, the LLM will truncate it, potentially losing critical information. Use tokenizers to estimate length.
*   **Semantic Search for RAG:** Leverage embeddings to retrieve relevant information from external knowledge bases. This allows you to provide highly specific and up-to-date context to your LLM, overcoming its inherent knowledge cutoff.
*   **Few-Shot Learning:** The effectiveness of few-shot examples (covered in Chapter 3) relies on the LLM's ability to understand the semantic relationship between the examples and the new query within its embedding space.
*   **Prompt Optimization:** Understanding that prompts are converted to vectors can inform how you phrase instructions. Semantically similar prompts will likely lead to similar internal representations, but subtle differences can shift the vector enough to alter output.

## Reflection

*   How does the concept of tokenization directly influence the practical constraints (like cost and length) you face when designing prompts for LLMs?
*   In what scenarios would calculating the cosine similarity of embeddings be a useful technique for a prompt engineer?
*   How does the idea of a "vector space" help you conceptualize how LLMs understand the meaning and relationships between words and sentences in your prompts?
*   Consider a situation where your prompt is too long. How would your understanding of tokenization guide your approach to shortening it without losing critical information?
