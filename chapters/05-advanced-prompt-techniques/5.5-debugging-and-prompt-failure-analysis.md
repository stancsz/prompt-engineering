# 5.5 Debugging and Prompt Failure Analysis

Understanding why prompts fail is crucial to iteratively refine them for reliability.

## Common Failure Modes

- **Hallucinations:** Model fabricates facts.  
- **Truncation:** Important context cut off due to token limits.  
- **Ambiguity:** Prompt phrasing yields inconsistent interpretations.  
- **Overfitting to Examples:** Few-shot templates bias undesired patterns.  

## Debugging Steps

1. **Reproduce Consistently:** Run multiple trials to confirm the failure.  
2. **Isolate Variables:** Change one parameter (role, examples, temperature) at a time.  
3. **Inspect Intermediate Outputs:** For chain-of-thought, verify each step.  
4. **Simplify Prompt:** Remove non-essential context to identify problematic segments.  

## Example

**Failing Prompt:**  
```
You are a fact checker. Is the statement “Napoleon was born in 1769” true or false?  
```

- Run 5 completions; observe mixed “True” / “False.”  
- Remove role: check if ambiguity decreases.  
- Add explicit instruction: “Explain your reasoning then answer.”  

## Hands-On Exercise

1. Identify a prompt that yields incorrect or inconsistent answers.  
2. Apply debugging steps: vary one factor per trial.  
3. Document how each change impacts reliability.  

## Reflection

- Which debugging step uncovered the root cause?  
- How did simplification vs. added instruction affect outcomes?  
- What lessons can you apply to future prompt designs?
