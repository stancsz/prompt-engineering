# 10.1 Sources of Bias in Data and Prompts

Bias can creep into AI systems through training data and prompt design, leading to unfair or skewed outputs.

## Key Concepts

- **Historical Bias:** Prejudices embedded in training corpora (e.g., underrepresented groups).  
- **Selection Bias:** Over- or under-sampling of certain topics, speakers, or dialects.  
- **Measurement Bias:** Inaccurate or inconsistent labeling in fine-tuning data.  
- **Prompt Bias:** Framing or examples that lead the model toward a particular viewpoint.

## Example

```
Prompt A: “List successful CEOs.”  
— Model may return mostly male names due to historical data.

Prompt B (Debiased):  
“You are an analyst. List five successful CEOs from diverse backgrounds across gender and ethnicity.”  
```

## Hands-On Exercise

1. Query an LLM for “famous scientists” without guidance; inspect demographic skew.  
2. Add explicit diversity constraints; compare the change.  
3. Analyze whether forced constraints affect factual accuracy.

## Reflection

- Which biases persisted even after reframing?  
- How did specificity in prompt reduce or surface bias?  
- What trade-offs emerged between diversity and relevance?
