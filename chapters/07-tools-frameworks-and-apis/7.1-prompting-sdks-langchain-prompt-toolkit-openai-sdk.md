# 7.1 Prompting SDKs (LangChain, Prompt-Toolkit, OpenAI SDK)

SDKs simplify prompt orchestration, caching, and integration with external data sources.

## Overview

- **LangChain**  
  - Chains, agents, memory, retrievers, and callbacks.  
  - Integrates with vector stores, databases, and APIs.  
- **Prompt-Toolkit**  
  - Interactive CLI prompt building; rich input validation.  
- **OpenAI SDK**  
  - Direct client for completions, chat, embeddings, and files.  
  - Built-in retry and rate-limit handling.

## Example (LangChain)

```python
from langchain import PromptTemplate, LLMChain
from langchain.chat_models import ChatOpenAI

template = PromptTemplate(
    input_variables=["topic"],
    template="You are an expert writer. Write a 3-bullet summary of {topic}."
)
chain = LLMChain(llm=ChatOpenAI(model_name="gpt-4", temperature=0.3), prompt=template)
print(chain.run("retrieval-augmented generation"))
```

## Hands-On Exercise

1. Install LangChain:  
   ```bash
   pip install langchain openai
   ```  
2. Write a script that:
   - Defines a `PromptTemplate` with two variables.  
   - Uses `LLMChain` to call GPT-4.  
   - Prints the formatted prompt and model response.  

3. Extend it to cache responses in memory and re-run with the same input to verify caching.

## Reflection

- How did the SDK improve code readability?  
- What boilerplate did it eliminate compared to raw API calls?  
- How might you use callbacks for logging or streaming?
