# 7.2 Notebook-Based Experimentation (Jupyter, Colab)

Interactive notebooks are ideal for exploring prompts, visualizing outputs, and iterating quickly.

## Why Notebooks?

- **Interactivity:** Run code, view outputs, modify prompts on the fly.  
- **Visualization:** Embed charts, logs, and attention maps inline.  
- **Shareability:** Save experiments as `.ipynb` and collaborate.

## Example Setup

1. Create a new Jupyter notebook (or Colab).  
2. Install SDKs:
   ```bash
   !pip install openai langchain jupyterlab
   ```
3. Initialize client and test a prompt cell:

   ```python
   from openai import OpenAI
   client = OpenAI(api_key="YOUR_KEY")
   response = client.chat.completions.create(
       model="gpt-4",
       messages=[{"role":"user","content":"Translate to French: 'Good morning.'"}]
   )
   print(response.choices[0].message.content)
   ```

## Hands-On Exercise

1. In a notebook cell, define a function `run_prompt(prompt, **kwargs)` that wraps an API call and returns text.  
2. Create a dataframe of 5 different prompt variants in pandas.  
3. Map `run_prompt` over the DataFrame, collect outputs.  
4. Display results side by side in a table.

## Visualization

- Use Pythonâ€™s `matplotlib` or `seaborn` to chart:
  - Token counts vs. response length.  
  - Temperature vs. diversity (e.g., unique token ratio).

```python
import seaborn as sns
sns.scatterplot(data=results, x='temperature', y='unique_ratio')
```

## Reflection

- How did immediate feedback affect prompt tuning?  
- Which visualizations revealed unexpected patterns?  
- How can you package notebook code into reusable scripts?
